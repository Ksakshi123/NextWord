{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2c3404b6-8184-4266-80f7-049668781115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Read the text file\n",
    "with open('sherlock_holmes_small.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c21de11a-ed48-4da1-bb38-f0a53dbf0708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "b93cfc3a-2a22-45e1-8a57-e9c6693166c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "0febfc74-13c2-4f65-b813-9b5f20ddc20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "5a790bf5-7d12-464f-a66b-5993be7e3b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'of': 2,\n",
       " 'and': 3,\n",
       " 'his': 4,\n",
       " 'to': 5,\n",
       " 'a': 6,\n",
       " 'in': 7,\n",
       " 'i': 8,\n",
       " 'was': 9,\n",
       " 'he': 10,\n",
       " 'for': 11,\n",
       " 'own': 12,\n",
       " 'which': 13,\n",
       " 'holmes': 14,\n",
       " 'that': 15,\n",
       " 'all': 16,\n",
       " 'but': 17,\n",
       " 'as': 18,\n",
       " 'from': 19,\n",
       " 'had': 20,\n",
       " 'my': 21,\n",
       " 'woman': 22,\n",
       " 'one': 23,\n",
       " 'were': 24,\n",
       " 'with': 25,\n",
       " 'up': 26,\n",
       " 'sherlock': 27,\n",
       " 'she': 28,\n",
       " 'have': 29,\n",
       " 'heard': 30,\n",
       " 'him': 31,\n",
       " 'her': 32,\n",
       " 'any': 33,\n",
       " 'other': 34,\n",
       " 'whole': 35,\n",
       " 'it': 36,\n",
       " 'not': 37,\n",
       " 'emotion': 38,\n",
       " 'irene': 39,\n",
       " 'adler': 40,\n",
       " 'seen': 41,\n",
       " 'would': 42,\n",
       " 'himself': 43,\n",
       " 'such': 44,\n",
       " 'nature': 45,\n",
       " 'little': 46,\n",
       " 'who': 47,\n",
       " 'week': 48,\n",
       " 'by': 49,\n",
       " 'those': 50,\n",
       " 'clearing': 51,\n",
       " 'time': 52,\n",
       " 'adventures': 53,\n",
       " 'is': 54,\n",
       " 'always': 55,\n",
       " 'seldom': 56,\n",
       " 'mention': 57,\n",
       " 'under': 58,\n",
       " 'name': 59,\n",
       " 'eyes': 60,\n",
       " 'eclipses': 61,\n",
       " 'predominates': 62,\n",
       " 'sex': 63,\n",
       " 'felt': 64,\n",
       " 'akin': 65,\n",
       " 'love': 66,\n",
       " 'emotions': 67,\n",
       " 'particularly': 68,\n",
       " 'abhorrent': 69,\n",
       " 'cold': 70,\n",
       " 'precise': 71,\n",
       " 'admirably': 72,\n",
       " 'balanced': 73,\n",
       " 'mind': 74,\n",
       " 'take': 75,\n",
       " 'most': 76,\n",
       " 'perfect': 77,\n",
       " 'reasoning': 78,\n",
       " 'observing': 79,\n",
       " 'machine': 80,\n",
       " 'world': 81,\n",
       " 'has': 82,\n",
       " 'lover': 83,\n",
       " 'placed': 84,\n",
       " 'false': 85,\n",
       " 'position': 86,\n",
       " 'never': 87,\n",
       " 'spoke': 88,\n",
       " 'softer': 89,\n",
       " 'passions': 90,\n",
       " 'save': 91,\n",
       " 'gibe': 92,\n",
       " 'sneer': 93,\n",
       " 'they': 94,\n",
       " 'admirable': 95,\n",
       " 'things': 96,\n",
       " 'observer': 97,\n",
       " 'excellent': 98,\n",
       " 'drawing': 99,\n",
       " 'veil': 100,\n",
       " \"men's\": 101,\n",
       " 'motives': 102,\n",
       " 'actions': 103,\n",
       " 'trained': 104,\n",
       " 'reasoner': 105,\n",
       " 'admit': 106,\n",
       " 'intrusions': 107,\n",
       " 'into': 108,\n",
       " 'delicate': 109,\n",
       " 'finely': 110,\n",
       " 'adjusted': 111,\n",
       " 'temperament': 112,\n",
       " 'introduce': 113,\n",
       " 'distracting': 114,\n",
       " 'factor': 115,\n",
       " 'might': 116,\n",
       " 'throw': 117,\n",
       " 'doubt': 118,\n",
       " 'upon': 119,\n",
       " 'mental': 120,\n",
       " 'results': 121,\n",
       " 'grit': 122,\n",
       " 'sensitive': 123,\n",
       " 'instrument': 124,\n",
       " 'or': 125,\n",
       " 'crack': 126,\n",
       " 'high': 127,\n",
       " 'power': 128,\n",
       " 'lenses': 129,\n",
       " 'be': 130,\n",
       " 'more': 131,\n",
       " 'disturbing': 132,\n",
       " 'than': 133,\n",
       " 'strong': 134,\n",
       " 'yet': 135,\n",
       " 'there': 136,\n",
       " 'late': 137,\n",
       " 'dubious': 138,\n",
       " 'questionable': 139,\n",
       " 'memory': 140,\n",
       " 'lately': 141,\n",
       " 'marriage': 142,\n",
       " 'drifted': 143,\n",
       " 'us': 144,\n",
       " 'away': 145,\n",
       " 'each': 146,\n",
       " 'complete': 147,\n",
       " 'happiness': 148,\n",
       " 'home': 149,\n",
       " 'centred': 150,\n",
       " 'interests': 151,\n",
       " 'rise': 152,\n",
       " 'around': 153,\n",
       " 'man': 154,\n",
       " 'first': 155,\n",
       " 'finds': 156,\n",
       " 'master': 157,\n",
       " 'establishment': 158,\n",
       " 'sufficient': 159,\n",
       " 'absorb': 160,\n",
       " 'attention': 161,\n",
       " 'while': 162,\n",
       " 'loathed': 163,\n",
       " 'every': 164,\n",
       " 'form': 165,\n",
       " 'society': 166,\n",
       " 'bohemian': 167,\n",
       " 'soul': 168,\n",
       " 'remained': 169,\n",
       " 'our': 170,\n",
       " 'lodgings': 171,\n",
       " 'baker': 172,\n",
       " 'street': 173,\n",
       " 'buried': 174,\n",
       " 'among': 175,\n",
       " 'old': 176,\n",
       " 'books': 177,\n",
       " 'alternating': 178,\n",
       " 'between': 179,\n",
       " 'cocaine': 180,\n",
       " 'ambition': 181,\n",
       " 'drowsiness': 182,\n",
       " 'drug': 183,\n",
       " 'fierce': 184,\n",
       " 'energy': 185,\n",
       " 'keen': 186,\n",
       " 'still': 187,\n",
       " 'ever': 188,\n",
       " 'deeply': 189,\n",
       " 'attracted': 190,\n",
       " 'study': 191,\n",
       " 'crime': 192,\n",
       " 'occupied': 193,\n",
       " 'immense': 194,\n",
       " 'faculties': 195,\n",
       " 'extraordinary': 196,\n",
       " 'powers': 197,\n",
       " 'observation': 198,\n",
       " 'following': 199,\n",
       " 'out': 200,\n",
       " 'clues': 201,\n",
       " 'mysteries': 202,\n",
       " 'been': 203,\n",
       " 'abandoned': 204,\n",
       " 'hopeless': 205,\n",
       " 'official': 206,\n",
       " 'police': 207,\n",
       " 'some': 208,\n",
       " 'vague': 209,\n",
       " 'account': 210,\n",
       " 'doings': 211,\n",
       " 'summons': 212,\n",
       " 'odessa': 213,\n",
       " 'case': 214,\n",
       " 'trepoff': 215,\n",
       " 'murder': 216,\n",
       " 'singular': 217,\n",
       " 'tragedy': 218,\n",
       " 'atkinson': 219,\n",
       " 'brothers': 220,\n",
       " 'at': 221,\n",
       " 'trincomalee': 222,\n",
       " 'finally': 223,\n",
       " 'mission': 224,\n",
       " 'accomplished': 225,\n",
       " 'so': 226,\n",
       " 'delicately': 227,\n",
       " 'successfully': 228,\n",
       " 'reigning': 229,\n",
       " 'family': 230,\n",
       " 'holland': 231,\n",
       " 'beyond': 232,\n",
       " 'these': 233,\n",
       " 'signs': 234,\n",
       " 'activity': 235,\n",
       " 'however': 236,\n",
       " 'merely': 237,\n",
       " 'shared': 238,\n",
       " 'readers': 239,\n",
       " 'daily': 240,\n",
       " 'press': 241,\n",
       " 'knew': 242,\n",
       " 'former': 243,\n",
       " 'friend': 244,\n",
       " 'companion': 245}"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "3cd4ba42-0ebf-4113-ac17-c4f839345aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "adf064a7-a8f3-45ac-b869-0758e9d64159",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = []\n",
    "for sentence in text.split('\\n'):\n",
    "    # //print(sentence)\n",
    "    tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequence.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c0208c0e-8b37-4ac2-847f-b3d1f2202fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 53],\n",
       " [1, 53, 2],\n",
       " [1, 53, 2, 27],\n",
       " [1, 53, 2, 27, 14],\n",
       " [5, 27],\n",
       " [5, 27, 14],\n",
       " [5, 27, 14, 28],\n",
       " [5, 27, 14, 28, 54],\n",
       " [5, 27, 14, 28, 54, 55],\n",
       " [5, 27, 14, 28, 54, 55, 1],\n",
       " [5, 27, 14, 28, 54, 55, 1, 22],\n",
       " [5, 27, 14, 28, 54, 55, 1, 22, 8],\n",
       " [5, 27, 14, 28, 54, 55, 1, 22, 8, 29],\n",
       " [5, 27, 14, 28, 54, 55, 1, 22, 8, 29, 56],\n",
       " [5, 27, 14, 28, 54, 55, 1, 22, 8, 29, 56, 30],\n",
       " [5, 27, 14, 28, 54, 55, 1, 22, 8, 29, 56, 30, 31],\n",
       " [57, 32],\n",
       " [57, 32, 58],\n",
       " [57, 32, 58, 33],\n",
       " [57, 32, 58, 33, 34],\n",
       " [57, 32, 58, 33, 34, 59],\n",
       " [57, 32, 58, 33, 34, 59, 7],\n",
       " [57, 32, 58, 33, 34, 59, 7, 4],\n",
       " [57, 32, 58, 33, 34, 59, 7, 4, 60],\n",
       " [57, 32, 58, 33, 34, 59, 7, 4, 60, 28],\n",
       " [57, 32, 58, 33, 34, 59, 7, 4, 60, 28, 61],\n",
       " [57, 32, 58, 33, 34, 59, 7, 4, 60, 28, 61, 3],\n",
       " [62, 1],\n",
       " [62, 1, 35],\n",
       " [62, 1, 35, 2],\n",
       " [62, 1, 35, 2, 32],\n",
       " [62, 1, 35, 2, 32, 63],\n",
       " [62, 1, 35, 2, 32, 63, 36],\n",
       " [62, 1, 35, 2, 32, 63, 36, 9],\n",
       " [62, 1, 35, 2, 32, 63, 36, 9, 37],\n",
       " [62, 1, 35, 2, 32, 63, 36, 9, 37, 15],\n",
       " [62, 1, 35, 2, 32, 63, 36, 9, 37, 15, 10],\n",
       " [62, 1, 35, 2, 32, 63, 36, 9, 37, 15, 10, 64],\n",
       " [62, 1, 35, 2, 32, 63, 36, 9, 37, 15, 10, 64, 33],\n",
       " [38, 65],\n",
       " [38, 65, 5],\n",
       " [38, 65, 5, 66],\n",
       " [38, 65, 5, 66, 11],\n",
       " [38, 65, 5, 66, 11, 39],\n",
       " [38, 65, 5, 66, 11, 39, 40],\n",
       " [38, 65, 5, 66, 11, 39, 40, 16],\n",
       " [38, 65, 5, 66, 11, 39, 40, 16, 67],\n",
       " [38, 65, 5, 66, 11, 39, 40, 16, 67, 3],\n",
       " [38, 65, 5, 66, 11, 39, 40, 16, 67, 3, 15],\n",
       " [38, 65, 5, 66, 11, 39, 40, 16, 67, 3, 15, 23],\n",
       " [68, 24],\n",
       " [68, 24, 69],\n",
       " [68, 24, 69, 5],\n",
       " [68, 24, 69, 5, 4],\n",
       " [68, 24, 69, 5, 4, 70],\n",
       " [68, 24, 69, 5, 4, 70, 71],\n",
       " [68, 24, 69, 5, 4, 70, 71, 17],\n",
       " [68, 24, 69, 5, 4, 70, 71, 17, 72],\n",
       " [73, 74],\n",
       " [73, 74, 10],\n",
       " [73, 74, 10, 9],\n",
       " [73, 74, 10, 9, 8],\n",
       " [73, 74, 10, 9, 8, 75],\n",
       " [73, 74, 10, 9, 8, 75, 36],\n",
       " [73, 74, 10, 9, 8, 75, 36, 1],\n",
       " [73, 74, 10, 9, 8, 75, 36, 1, 76],\n",
       " [73, 74, 10, 9, 8, 75, 36, 1, 76, 77],\n",
       " [73, 74, 10, 9, 8, 75, 36, 1, 76, 77, 78],\n",
       " [73, 74, 10, 9, 8, 75, 36, 1, 76, 77, 78, 3],\n",
       " [79, 80],\n",
       " [79, 80, 15],\n",
       " [79, 80, 15, 1],\n",
       " [79, 80, 15, 1, 81],\n",
       " [79, 80, 15, 1, 81, 82],\n",
       " [79, 80, 15, 1, 81, 82, 41],\n",
       " [79, 80, 15, 1, 81, 82, 41, 17],\n",
       " [79, 80, 15, 1, 81, 82, 41, 17, 18],\n",
       " [79, 80, 15, 1, 81, 82, 41, 17, 18, 6],\n",
       " [79, 80, 15, 1, 81, 82, 41, 17, 18, 6, 83],\n",
       " [79, 80, 15, 1, 81, 82, 41, 17, 18, 6, 83, 10],\n",
       " [79, 80, 15, 1, 81, 82, 41, 17, 18, 6, 83, 10, 42],\n",
       " [29, 84],\n",
       " [29, 84, 43],\n",
       " [29, 84, 43, 7],\n",
       " [29, 84, 43, 7, 6],\n",
       " [29, 84, 43, 7, 6, 85],\n",
       " [29, 84, 43, 7, 6, 85, 86],\n",
       " [29, 84, 43, 7, 6, 85, 86, 10],\n",
       " [29, 84, 43, 7, 6, 85, 86, 10, 87],\n",
       " [29, 84, 43, 7, 6, 85, 86, 10, 87, 88],\n",
       " [29, 84, 43, 7, 6, 85, 86, 10, 87, 88, 2],\n",
       " [29, 84, 43, 7, 6, 85, 86, 10, 87, 88, 2, 1],\n",
       " [29, 84, 43, 7, 6, 85, 86, 10, 87, 88, 2, 1, 89],\n",
       " [90, 91],\n",
       " [90, 91, 25],\n",
       " [90, 91, 25, 6],\n",
       " [90, 91, 25, 6, 92],\n",
       " [90, 91, 25, 6, 92, 3],\n",
       " [90, 91, 25, 6, 92, 3, 6],\n",
       " [90, 91, 25, 6, 92, 3, 6, 93],\n",
       " [90, 91, 25, 6, 92, 3, 6, 93, 94],\n",
       " [90, 91, 25, 6, 92, 3, 6, 93, 94, 24],\n",
       " [90, 91, 25, 6, 92, 3, 6, 93, 94, 24, 95],\n",
       " [90, 91, 25, 6, 92, 3, 6, 93, 94, 24, 95, 96],\n",
       " [11, 1],\n",
       " [11, 1, 97],\n",
       " [11, 1, 97, 98],\n",
       " [11, 1, 97, 98, 11],\n",
       " [11, 1, 97, 98, 11, 99],\n",
       " [11, 1, 97, 98, 11, 99, 1],\n",
       " [11, 1, 97, 98, 11, 99, 1, 100],\n",
       " [11, 1, 97, 98, 11, 99, 1, 100, 19],\n",
       " [11, 1, 97, 98, 11, 99, 1, 100, 19, 101],\n",
       " [11, 1, 97, 98, 11, 99, 1, 100, 19, 101, 102],\n",
       " [3, 103],\n",
       " [3, 103, 17],\n",
       " [3, 103, 17, 11],\n",
       " [3, 103, 17, 11, 1],\n",
       " [3, 103, 17, 11, 1, 104],\n",
       " [3, 103, 17, 11, 1, 104, 105],\n",
       " [3, 103, 17, 11, 1, 104, 105, 5],\n",
       " [3, 103, 17, 11, 1, 104, 105, 5, 106],\n",
       " [3, 103, 17, 11, 1, 104, 105, 5, 106, 44],\n",
       " [3, 103, 17, 11, 1, 104, 105, 5, 106, 44, 107],\n",
       " [108, 4],\n",
       " [108, 4, 12],\n",
       " [108, 4, 12, 109],\n",
       " [108, 4, 12, 109, 3],\n",
       " [108, 4, 12, 109, 3, 110],\n",
       " [108, 4, 12, 109, 3, 110, 111],\n",
       " [108, 4, 12, 109, 3, 110, 111, 112],\n",
       " [108, 4, 12, 109, 3, 110, 111, 112, 9],\n",
       " [108, 4, 12, 109, 3, 110, 111, 112, 9, 5],\n",
       " [113, 6],\n",
       " [113, 6, 114],\n",
       " [113, 6, 114, 115],\n",
       " [113, 6, 114, 115, 13],\n",
       " [113, 6, 114, 115, 13, 116],\n",
       " [113, 6, 114, 115, 13, 116, 117],\n",
       " [113, 6, 114, 115, 13, 116, 117, 6],\n",
       " [113, 6, 114, 115, 13, 116, 117, 6, 118],\n",
       " [113, 6, 114, 115, 13, 116, 117, 6, 118, 119],\n",
       " [113, 6, 114, 115, 13, 116, 117, 6, 118, 119, 16],\n",
       " [113, 6, 114, 115, 13, 116, 117, 6, 118, 119, 16, 4],\n",
       " [120, 121],\n",
       " [120, 121, 122],\n",
       " [120, 121, 122, 7],\n",
       " [120, 121, 122, 7, 6],\n",
       " [120, 121, 122, 7, 6, 123],\n",
       " [120, 121, 122, 7, 6, 123, 124],\n",
       " [120, 121, 122, 7, 6, 123, 124, 125],\n",
       " [120, 121, 122, 7, 6, 123, 124, 125, 6],\n",
       " [120, 121, 122, 7, 6, 123, 124, 125, 6, 126],\n",
       " [120, 121, 122, 7, 6, 123, 124, 125, 6, 126, 7],\n",
       " [120, 121, 122, 7, 6, 123, 124, 125, 6, 126, 7, 23],\n",
       " [120, 121, 122, 7, 6, 123, 124, 125, 6, 126, 7, 23, 2],\n",
       " [4, 12],\n",
       " [4, 12, 127],\n",
       " [4, 12, 127, 128],\n",
       " [4, 12, 127, 128, 129],\n",
       " [4, 12, 127, 128, 129, 42],\n",
       " [4, 12, 127, 128, 129, 42, 37],\n",
       " [4, 12, 127, 128, 129, 42, 37, 130],\n",
       " [4, 12, 127, 128, 129, 42, 37, 130, 131],\n",
       " [4, 12, 127, 128, 129, 42, 37, 130, 131, 132],\n",
       " [4, 12, 127, 128, 129, 42, 37, 130, 131, 132, 133],\n",
       " [4, 12, 127, 128, 129, 42, 37, 130, 131, 132, 133, 6],\n",
       " [4, 12, 127, 128, 129, 42, 37, 130, 131, 132, 133, 6, 134],\n",
       " [38, 7],\n",
       " [38, 7, 6],\n",
       " [38, 7, 6, 45],\n",
       " [38, 7, 6, 45, 44],\n",
       " [38, 7, 6, 45, 44, 18],\n",
       " [38, 7, 6, 45, 44, 18, 4],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135, 136],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135, 136, 9],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135, 136, 9, 17],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135, 136, 9, 17, 23],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135, 136, 9, 17, 23, 22],\n",
       " [38, 7, 6, 45, 44, 18, 4, 3, 135, 136, 9, 17, 23, 22, 5],\n",
       " [31, 3],\n",
       " [31, 3, 15],\n",
       " [31, 3, 15, 22],\n",
       " [31, 3, 15, 22, 9],\n",
       " [31, 3, 15, 22, 9, 1],\n",
       " [31, 3, 15, 22, 9, 1, 137],\n",
       " [31, 3, 15, 22, 9, 1, 137, 39],\n",
       " [31, 3, 15, 22, 9, 1, 137, 39, 40],\n",
       " [31, 3, 15, 22, 9, 1, 137, 39, 40, 2],\n",
       " [31, 3, 15, 22, 9, 1, 137, 39, 40, 2, 138],\n",
       " [31, 3, 15, 22, 9, 1, 137, 39, 40, 2, 138, 3],\n",
       " [139, 140],\n",
       " [8, 20],\n",
       " [8, 20, 41],\n",
       " [8, 20, 41, 46],\n",
       " [8, 20, 41, 46, 2],\n",
       " [8, 20, 41, 46, 2, 14],\n",
       " [8, 20, 41, 46, 2, 14, 141],\n",
       " [8, 20, 41, 46, 2, 14, 141, 21],\n",
       " [8, 20, 41, 46, 2, 14, 141, 21, 142],\n",
       " [8, 20, 41, 46, 2, 14, 141, 21, 142, 20],\n",
       " [8, 20, 41, 46, 2, 14, 141, 21, 142, 20, 143],\n",
       " [8, 20, 41, 46, 2, 14, 141, 21, 142, 20, 143, 144],\n",
       " [8, 20, 41, 46, 2, 14, 141, 21, 142, 20, 143, 144, 145],\n",
       " [19, 146],\n",
       " [19, 146, 34],\n",
       " [19, 146, 34, 21],\n",
       " [19, 146, 34, 21, 12],\n",
       " [19, 146, 34, 21, 12, 147],\n",
       " [19, 146, 34, 21, 12, 147, 148],\n",
       " [19, 146, 34, 21, 12, 147, 148, 3],\n",
       " [19, 146, 34, 21, 12, 147, 148, 3, 1],\n",
       " [19, 146, 34, 21, 12, 147, 148, 3, 1, 149],\n",
       " [19, 146, 34, 21, 12, 147, 148, 3, 1, 149, 150],\n",
       " [151, 13],\n",
       " [151, 13, 152],\n",
       " [151, 13, 152, 26],\n",
       " [151, 13, 152, 26, 153],\n",
       " [151, 13, 152, 26, 153, 1],\n",
       " [151, 13, 152, 26, 153, 1, 154],\n",
       " [151, 13, 152, 26, 153, 1, 154, 47],\n",
       " [151, 13, 152, 26, 153, 1, 154, 47, 155],\n",
       " [151, 13, 152, 26, 153, 1, 154, 47, 155, 156],\n",
       " [151, 13, 152, 26, 153, 1, 154, 47, 155, 156, 43],\n",
       " [151, 13, 152, 26, 153, 1, 154, 47, 155, 156, 43, 157],\n",
       " [2, 4],\n",
       " [2, 4, 12],\n",
       " [2, 4, 12, 158],\n",
       " [2, 4, 12, 158, 24],\n",
       " [2, 4, 12, 158, 24, 159],\n",
       " [2, 4, 12, 158, 24, 159, 5],\n",
       " [2, 4, 12, 158, 24, 159, 5, 160],\n",
       " [2, 4, 12, 158, 24, 159, 5, 160, 16],\n",
       " [2, 4, 12, 158, 24, 159, 5, 160, 16, 21],\n",
       " [2, 4, 12, 158, 24, 159, 5, 160, 16, 21, 161],\n",
       " [162, 14],\n",
       " [162, 14, 47],\n",
       " [162, 14, 47, 163],\n",
       " [162, 14, 47, 163, 164],\n",
       " [162, 14, 47, 163, 164, 165],\n",
       " [162, 14, 47, 163, 164, 165, 2],\n",
       " [162, 14, 47, 163, 164, 165, 2, 166],\n",
       " [162, 14, 47, 163, 164, 165, 2, 166, 25],\n",
       " [162, 14, 47, 163, 164, 165, 2, 166, 25, 4],\n",
       " [162, 14, 47, 163, 164, 165, 2, 166, 25, 4, 35],\n",
       " [167, 168],\n",
       " [167, 168, 169],\n",
       " [167, 168, 169, 7],\n",
       " [167, 168, 169, 7, 170],\n",
       " [167, 168, 169, 7, 170, 171],\n",
       " [167, 168, 169, 7, 170, 171, 7],\n",
       " [167, 168, 169, 7, 170, 171, 7, 172],\n",
       " [167, 168, 169, 7, 170, 171, 7, 172, 173],\n",
       " [167, 168, 169, 7, 170, 171, 7, 172, 173, 174],\n",
       " [167, 168, 169, 7, 170, 171, 7, 172, 173, 174, 175],\n",
       " [4, 176],\n",
       " [4, 176, 177],\n",
       " [4, 176, 177, 3],\n",
       " [4, 176, 177, 3, 178],\n",
       " [4, 176, 177, 3, 178, 19],\n",
       " [4, 176, 177, 3, 178, 19, 48],\n",
       " [4, 176, 177, 3, 178, 19, 48, 5],\n",
       " [4, 176, 177, 3, 178, 19, 48, 5, 48],\n",
       " [4, 176, 177, 3, 178, 19, 48, 5, 48, 179],\n",
       " [4, 176, 177, 3, 178, 19, 48, 5, 48, 179, 180],\n",
       " [4, 176, 177, 3, 178, 19, 48, 5, 48, 179, 180, 3],\n",
       " [181, 1],\n",
       " [181, 1, 182],\n",
       " [181, 1, 182, 2],\n",
       " [181, 1, 182, 2, 1],\n",
       " [181, 1, 182, 2, 1, 183],\n",
       " [181, 1, 182, 2, 1, 183, 3],\n",
       " [181, 1, 182, 2, 1, 183, 3, 1],\n",
       " [181, 1, 182, 2, 1, 183, 3, 1, 184],\n",
       " [181, 1, 182, 2, 1, 183, 3, 1, 184, 185],\n",
       " [181, 1, 182, 2, 1, 183, 3, 1, 184, 185, 2],\n",
       " [181, 1, 182, 2, 1, 183, 3, 1, 184, 185, 2, 4],\n",
       " [12, 186],\n",
       " [12, 186, 45],\n",
       " [12, 186, 45, 10],\n",
       " [12, 186, 45, 10, 9],\n",
       " [12, 186, 45, 10, 9, 187],\n",
       " [12, 186, 45, 10, 9, 187, 18],\n",
       " [12, 186, 45, 10, 9, 187, 18, 188],\n",
       " [12, 186, 45, 10, 9, 187, 18, 188, 189],\n",
       " [12, 186, 45, 10, 9, 187, 18, 188, 189, 190],\n",
       " [12, 186, 45, 10, 9, 187, 18, 188, 189, 190, 49],\n",
       " [12, 186, 45, 10, 9, 187, 18, 188, 189, 190, 49, 1],\n",
       " [12, 186, 45, 10, 9, 187, 18, 188, 189, 190, 49, 1, 191],\n",
       " [2, 192],\n",
       " [2, 192, 3],\n",
       " [2, 192, 3, 193],\n",
       " [2, 192, 3, 193, 4],\n",
       " [2, 192, 3, 193, 4, 194],\n",
       " [2, 192, 3, 193, 4, 194, 195],\n",
       " [2, 192, 3, 193, 4, 194, 195, 3],\n",
       " [2, 192, 3, 193, 4, 194, 195, 3, 196],\n",
       " [2, 192, 3, 193, 4, 194, 195, 3, 196, 197],\n",
       " [2, 198],\n",
       " [2, 198, 7],\n",
       " [2, 198, 7, 199],\n",
       " [2, 198, 7, 199, 200],\n",
       " [2, 198, 7, 199, 200, 50],\n",
       " [2, 198, 7, 199, 200, 50, 201],\n",
       " [2, 198, 7, 199, 200, 50, 201, 3],\n",
       " [2, 198, 7, 199, 200, 50, 201, 3, 51],\n",
       " [2, 198, 7, 199, 200, 50, 201, 3, 51, 26],\n",
       " [2, 198, 7, 199, 200, 50, 201, 3, 51, 26, 50],\n",
       " [202, 13],\n",
       " [202, 13, 20],\n",
       " [202, 13, 20, 203],\n",
       " [202, 13, 20, 203, 204],\n",
       " [202, 13, 20, 203, 204, 18],\n",
       " [202, 13, 20, 203, 204, 18, 205],\n",
       " [202, 13, 20, 203, 204, 18, 205, 49],\n",
       " [202, 13, 20, 203, 204, 18, 205, 49, 1],\n",
       " [202, 13, 20, 203, 204, 18, 205, 49, 1, 206],\n",
       " [207, 19],\n",
       " [207, 19, 52],\n",
       " [207, 19, 52, 5],\n",
       " [207, 19, 52, 5, 52],\n",
       " [207, 19, 52, 5, 52, 8],\n",
       " [207, 19, 52, 5, 52, 8, 30],\n",
       " [207, 19, 52, 5, 52, 8, 30, 208],\n",
       " [207, 19, 52, 5, 52, 8, 30, 208, 209],\n",
       " [207, 19, 52, 5, 52, 8, 30, 208, 209, 210],\n",
       " [207, 19, 52, 5, 52, 8, 30, 208, 209, 210, 2],\n",
       " [207, 19, 52, 5, 52, 8, 30, 208, 209, 210, 2, 4],\n",
       " [207, 19, 52, 5, 52, 8, 30, 208, 209, 210, 2, 4, 211],\n",
       " [2, 4],\n",
       " [2, 4, 212],\n",
       " [2, 4, 212, 5],\n",
       " [2, 4, 212, 5, 213],\n",
       " [2, 4, 212, 5, 213, 7],\n",
       " [2, 4, 212, 5, 213, 7, 1],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214, 2],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214, 2, 1],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214, 2, 1, 215],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214, 2, 1, 215, 216],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214, 2, 1, 215, 216, 2],\n",
       " [2, 4, 212, 5, 213, 7, 1, 214, 2, 1, 215, 216, 2, 4],\n",
       " [51, 26],\n",
       " [51, 26, 2],\n",
       " [51, 26, 2, 1],\n",
       " [51, 26, 2, 1, 217],\n",
       " [51, 26, 2, 1, 217, 218],\n",
       " [51, 26, 2, 1, 217, 218, 2],\n",
       " [51, 26, 2, 1, 217, 218, 2, 1],\n",
       " [51, 26, 2, 1, 217, 218, 2, 1, 219],\n",
       " [51, 26, 2, 1, 217, 218, 2, 1, 219, 220],\n",
       " [51, 26, 2, 1, 217, 218, 2, 1, 219, 220, 221],\n",
       " [222, 3],\n",
       " [222, 3, 223],\n",
       " [222, 3, 223, 2],\n",
       " [222, 3, 223, 2, 1],\n",
       " [222, 3, 223, 2, 1, 224],\n",
       " [222, 3, 223, 2, 1, 224, 13],\n",
       " [222, 3, 223, 2, 1, 224, 13, 10],\n",
       " [222, 3, 223, 2, 1, 224, 13, 10, 20],\n",
       " [222, 3, 223, 2, 1, 224, 13, 10, 20, 225],\n",
       " [222, 3, 223, 2, 1, 224, 13, 10, 20, 225, 226],\n",
       " [227, 3],\n",
       " [227, 3, 228],\n",
       " [227, 3, 228, 11],\n",
       " [227, 3, 228, 11, 1],\n",
       " [227, 3, 228, 11, 1, 229],\n",
       " [227, 3, 228, 11, 1, 229, 230],\n",
       " [227, 3, 228, 11, 1, 229, 230, 2],\n",
       " [227, 3, 228, 11, 1, 229, 230, 2, 231],\n",
       " [232, 233],\n",
       " [232, 233, 234],\n",
       " [232, 233, 234, 2],\n",
       " [232, 233, 234, 2, 4],\n",
       " [232, 233, 234, 2, 4, 235],\n",
       " [232, 233, 234, 2, 4, 235, 236],\n",
       " [232, 233, 234, 2, 4, 235, 236, 13],\n",
       " [232, 233, 234, 2, 4, 235, 236, 13, 8],\n",
       " [232, 233, 234, 2, 4, 235, 236, 13, 8, 237],\n",
       " [232, 233, 234, 2, 4, 235, 236, 13, 8, 237, 238],\n",
       " [25, 16],\n",
       " [25, 16, 1],\n",
       " [25, 16, 1, 239],\n",
       " [25, 16, 1, 239, 2],\n",
       " [25, 16, 1, 239, 2, 1],\n",
       " [25, 16, 1, 239, 2, 1, 240],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241, 8],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241, 8, 242],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241, 8, 242, 46],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241, 8, 242, 46, 2],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241, 8, 242, 46, 2, 21],\n",
       " [25, 16, 1, 239, 2, 1, 240, 241, 8, 242, 46, 2, 21, 243],\n",
       " [244, 3],\n",
       " [244, 3, 245]]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a8a02-70d7-4e6b-bd2a-a51e9507519f",
   "metadata": {},
   "source": [
    "The sequences are not in same length hence we apply zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "4cba9c83-7c51-4576-a501-5d58ac772a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(x) for x in input_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "73033ba3-c98b-43c2-94b6-8914e47f2b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences = pad_sequences(input_sequence,maxlen = max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "d8d712f4-073a-4504-b5a9-90216a3d8839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   1,  53],\n",
       "       [  0,   0,   0, ...,   1,  53,   2],\n",
       "       [  0,   0,   0, ...,  53,   2,  27],\n",
       "       ...,\n",
       "       [  0,  25,  16, ...,   2,  21, 243],\n",
       "       [  0,   0,   0, ...,   0, 244,   3],\n",
       "       [  0,   0,   0, ..., 244,   3, 245]], dtype=int32)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "5a96c144-f5df-4383-a0c1-18da709bd798",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padded_input_sequences[:,:-1]\n",
    "y = padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ab6f0171-dc9b-42fb-992f-11fb7e5068a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = len(tokenizer.word_index)+1 #unique words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "629a6d18-67f3-4cf6-9bc9-956e0a40ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "3d5e98d9-2c16-4edf-b78d-96178f3ded44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 246)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "47d6d732-5a9f-4ba1-9eae-a1b735480004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "7389579d-10de-419f-b0be-b0e499d69393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "359face3-5479-4fa8-b4c7-5dc40d4bcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words,100,input_length = max_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "c2e249a8-71e9-4104-9fbc-1d1abc907489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.9643 - loss: 0.6496\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9737 - loss: 0.5754 \n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9890 - loss: 0.5018 \n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9829 - loss: 0.4669\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9815 - loss: 0.4505\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9822 - loss: 0.4041\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9816 - loss: 0.3890 \n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9731 - loss: 0.3671 \n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9705 - loss: 0.3439\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9885 - loss: 0.2991 \n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9896 - loss: 0.2937\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9776 - loss: 0.2829\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9872 - loss: 0.2549 \n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9898 - loss: 0.2355 \n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9829 - loss: 0.2287\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9840 - loss: 0.2165\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9915 - loss: 0.1979 \n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9866 - loss: 0.1889\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9898 - loss: 0.1747\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9817 - loss: 0.1905 \n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9935 - loss: 0.1595\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9911 - loss: 0.1588\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9885 - loss: 0.1459\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9867 - loss: 0.1510\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9837 - loss: 0.1288\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9944 - loss: 0.1309\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9885 - loss: 0.1205 \n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9913 - loss: 0.1224 \n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9900 - loss: 0.1116 \n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9890 - loss: 0.1111\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9850 - loss: 0.1043\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9837 - loss: 0.0961 \n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9880 - loss: 0.0990 \n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9886 - loss: 0.0864 \n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9820 - loss: 0.0922\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9888 - loss: 0.0840 \n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.9924 - loss: 0.0794 \n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9933 - loss: 0.0807 \n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9856 - loss: 0.0794 \n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9875 - loss: 0.0789 \n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9939 - loss: 0.0677 \n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9907 - loss: 0.0706 \n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9892 - loss: 0.0624 \n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9897 - loss: 0.0616\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.9903 - loss: 0.0614\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.9882 - loss: 0.0681 \n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9800 - loss: 0.0673 \n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9679 - loss: 0.0764\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9877 - loss: 0.0639\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9933 - loss: 0.0600 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1de9bf48830>"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "e2c84ec4-c0c7-4c7a-b0cb-e30f71ab7e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">246</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">37,146</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │          \u001b[38;5;34m24,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │         \u001b[38;5;34m150,600\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m246\u001b[0m)                 │          \u001b[38;5;34m37,146\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">637,040</span> (2.43 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m637,040\u001b[0m (2.43 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,346</span> (829.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,346\u001b[0m (829.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">424,694</span> (1.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m424,694\u001b[0m (1.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "6325bdd9-093d-4df3-940c-25a29b979a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Holmes placed\n",
      "Mr. Holmes placed himself\n",
      "Mr. Holmes placed himself in\n",
      "Mr. Holmes placed himself in a\n",
      "Mr. Holmes placed himself in a nature\n",
      "Mr. Holmes placed himself in a nature such\n",
      "Mr. Holmes placed himself in a nature such as\n",
      "Mr. Holmes placed himself in a nature such as his\n",
      "Mr. Holmes placed himself in a nature such as his activity\n",
      "Mr. Holmes placed himself in a nature such as his activity however\n"
     ]
    }
   ],
   "source": [
    "ip = 'Mr. Holmes'\n",
    "for i in range(10):\n",
    "    # tokenize the current text\n",
    "    token_text = tokenizer.texts_to_sequences([ip])[0]\n",
    "    # pad the sequence\n",
    "    padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "    # predict probabilities\n",
    "    pred_probs = model.predict(padded_token_text, verbose=0)[0]\n",
    "    # choose next word using np.argmax (or sampling)\n",
    "    next_index = np.argmax(pred_probs)\n",
    "    \n",
    "    # convert index to word\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == next_index:\n",
    "            ip += \" \" + word\n",
    "            print(ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5daca9-8cfe-4553-a222-9ba306efcd28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
